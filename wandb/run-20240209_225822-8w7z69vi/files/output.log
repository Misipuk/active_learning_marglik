
Pool shape : torch.Size([40000, 1, 28, 28])
Starting epig acquisition
Using original estimate_epig function
epig_use_logprobs:True
[run_acq_epig_marglik_40k.py:192]INFO: Initial test log-likelihood: -3.4912
[run_acq_epig_marglik_40k.py:193]INFO: Initial test Bayes log-likelihood: -2.2860
[run_acq_epig_marglik_40k.py:194]INFO: Initial accuracy: 57.33%
We are in concat
[run_acq_epig_marglik_40k.py:233]INFO: Test log-likelihood at 21: -3.1907
[run_acq_epig_marglik_40k.py:234]INFO: Test Bayes log-likelihood at 21: -2.2847
[run_acq_epig_marglik_40k.py:235]INFO: Test accuracy: 58.29%
Starting epig acquisition
Using original estimate_epig function
epig_use_logprobs:True
We are in concat
[run_acq_epig_marglik_40k.py:233]INFO: Test log-likelihood at 22: -2.6375
[run_acq_epig_marglik_40k.py:234]INFO: Test Bayes log-likelihood at 22: -2.2948
[run_acq_epig_marglik_40k.py:235]INFO: Test accuracy: 61.71%
Starting epig acquisition
Using original estimate_epig function
epig_use_logprobs:True
We are in concat
Starting epig acquisition
Using original estimate_epig function
epig_use_logprobs:True
[run_acq_epig_marglik_40k.py:233]INFO: Test log-likelihood at 23: -2.0234
[run_acq_epig_marglik_40k.py:234]INFO: Test Bayes log-likelihood at 23: -2.3053
[run_acq_epig_marglik_40k.py:235]INFO: Test accuracy: 66.71%
We are in concat
[run_acq_epig_marglik_40k.py:233]INFO: Test log-likelihood at 24: -2.2324
[run_acq_epig_marglik_40k.py:234]INFO: Test Bayes log-likelihood at 24: -2.2611
[run_acq_epig_marglik_40k.py:235]INFO: Test accuracy: 64.06%
Starting epig acquisition
Using original estimate_epig function
epig_use_logprobs:True
We are in concat
[run_acq_epig_marglik_40k.py:233]INFO: Test log-likelihood at 25: -1.9899
[run_acq_epig_marglik_40k.py:234]INFO: Test Bayes log-likelihood at 25: -2.2204
[run_acq_epig_marglik_40k.py:235]INFO: Test accuracy: 66.07%
Starting epig acquisition
Using original estimate_epig function
epig_use_logprobs:True
Traceback (most recent call last):
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 72, in estimate_epig_minibatch_logprobs
    f_mu, f_var = m_model.la._glm_predictive_distribution(combined_inputs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 680, in _glm_predictive_distribution
    f_var = self.functional_variance(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 944, in functional_variance
    return self.posterior_precision.inv_square_form(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 406, in inv_square_form
    SW = self._bmm(W, exponent=-1)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 396, in _bmm
    W_p = Q1 @ W_p @ Q2.T
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 15.89 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 14.21 GiB memory in use. Of the allocated memory 9.11 GiB is allocated by PyTorch, and 4.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 304, in <module>
    main(**args)
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 219, in main
    scores = estimate_epig(learner, dataset.get_pool_loader(batch_size=batch_size), target_inputs, cfg.acquisition.epig_using_matmul, epig_use_logprobs)
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 53, in estimate_epig
    epig_scores = estimate_epig_minibatch_logprobs(m_model, inputs, target_inputs, use_matmul)  # [B,]
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 77, in estimate_epig_minibatch_logprobs
    f_mu, f_var = m_model.la._glm_predictive_distribution(combined_inputs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 680, in _glm_predictive_distribution
    f_var = self.functional_variance(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 944, in functional_variance
    return self.posterior_precision.inv_square_form(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 406, in inv_square_form
    SW = self._bmm(W, exponent=-1)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 395, in _bmm
    W_p = (Q1.T @ W_p @ Q2) * ldelta_exp
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 15.89 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 14.21 GiB memory in use. Of the allocated memory 10.51 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 72, in estimate_epig_minibatch_logprobs
    f_mu, f_var = m_model.la._glm_predictive_distribution(combined_inputs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 680, in _glm_predictive_distribution
    f_var = self.functional_variance(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 944, in functional_variance
    return self.posterior_precision.inv_square_form(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 406, in inv_square_form
    SW = self._bmm(W, exponent=-1)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 396, in _bmm
    W_p = Q1 @ W_p @ Q2.T
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 15.89 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 14.21 GiB memory in use. Of the allocated memory 9.11 GiB is allocated by PyTorch, and 4.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 304, in <module>
    main(**args)
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 219, in main
    scores = estimate_epig(learner, dataset.get_pool_loader(batch_size=batch_size), target_inputs, cfg.acquisition.epig_using_matmul, epig_use_logprobs)
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 53, in estimate_epig
    epig_scores = estimate_epig_minibatch_logprobs(m_model, inputs, target_inputs, use_matmul)  # [B,]
  File "/dss/dsshome1/0D/ge32jaq2/epig_plus_orig_marglik/active_learning_marglik/run_acq_epig_marglik_40k.py", line 77, in estimate_epig_minibatch_logprobs
    f_mu, f_var = m_model.la._glm_predictive_distribution(combined_inputs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 680, in _glm_predictive_distribution
    f_var = self.functional_variance(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/baselaplace.py", line 944, in functional_variance
    return self.posterior_precision.inv_square_form(Js)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 406, in inv_square_form
    SW = self._bmm(W, exponent=-1)
  File "/usr/local/lib/python3.10/dist-packages/laplace/utils/matrix.py", line 395, in _bmm
    W_p = (Q1.T @ W_p @ Q2) * ldelta_exp
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 15.89 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 14.21 GiB memory in use. Of the allocated memory 10.51 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF